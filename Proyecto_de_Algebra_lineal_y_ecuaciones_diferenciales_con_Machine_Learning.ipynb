{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Proyecto de Algebra lineal y ecuaciones diferenciales con Machine Learning.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOM3+ZxCwIW46WoWqbYMjfP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RachitVargas/Proyecto-de-algebra-lineal-con-aplicacion-de-machine-learning/blob/main/Proyecto_de_Algebra_lineal_y_ecuaciones_diferenciales_con_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu-TnaHwv_NN",
        "outputId": "d9ce8d7d-0d87-4dab-9a6a-34f590da61b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpzhattBKypT"
      },
      "source": [
        "# Proyecto de Algebra lineal y ecuaciones diferenciales con Machine Learning\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhfB58IDMPEL"
      },
      "source": [
        "### Importando librerias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MChTa0vUvr8S"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2lVD4IejXV1"
      },
      "source": [
        "### Cargando los datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3W4diaZNEzK"
      },
      "source": [
        "file_name = ('fh_5yrs.csv')\n",
        "dataframe = pd.read_csv(file_name)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKw0qmffdqQB"
      },
      "source": [
        "### Consultando la data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyP7Mrt3NWzP"
      },
      "source": [
        "# head para obtener las primeras 10 filas del dataframe\n",
        "dataframe.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaVMy0WtN8QO"
      },
      "source": [
        "# Consulta el tamnio de la data y la informacion\n",
        "print(len(dataframe))\n",
        "print(dataframe.info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E04cJ1zxk2HN"
      },
      "source": [
        "# Consulta el tipo de dato de cada columna del dataframe\n",
        "dataframe.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltJoKdH2mOh7"
      },
      "source": [
        "### Cambiando formato fecha la columna \"date\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTA8NvYHhurJ"
      },
      "source": [
        "# Cambiando formato fecha la columna \"date\"\n",
        "dataframe['date'] = pd.to_datetime(dataframe['date'], errors='coerce')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm0hCcJvl0DU"
      },
      "source": [
        "# Se consulta de nuevo el tipo de dato de cada columna para ver si se cambio el tipo de dato de la columna 'date'\n",
        "dataframe.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXcBwWPHg8Dx"
      },
      "source": [
        "### Eliminando valores NaN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1rZZiiReqQp"
      },
      "source": [
        "# Se suma en cada columna la cantidad de valores perdidos\n",
        "dataframe.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp8scmuUgTwx"
      },
      "source": [
        "# Eliminamos los valores perdidos\n",
        "dataframe = dataframe.dropna()\n",
        "dataframe.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_0xXEmAhCCH"
      },
      "source": [
        "### Dividiendo la data en:\n",
        "\n",
        "\n",
        "1.   60% entrenamiento\n",
        "2.   20% validacion\n",
        "3.   20% prueba\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAnVGDUxNhQz"
      },
      "source": [
        "# en la variable tam guardo el tamanio de la data\n",
        "tam = len(dataframe)\n",
        "# en tam_val guardo el 20% del tamnio de tam\n",
        "tam_val = int(0.2 * tam)\n",
        "# en tam_test guardo el 20% del tamnio de tam\n",
        "tam_test = int(0.2 * tam)\n",
        "# en tam_train guardo lo que resta de tam_val y tam_test, es decir, el 60% del tamnio de la tada  \n",
        "tam_train = int(tam - (tam_val + tam_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQq6NlNymWyu"
      },
      "source": [
        "# Establecemos un numero random estatico con una semilla de 2\n",
        "np.random.seed(2)\n",
        "# Creamos una variable indice para almacenar un vector de tamnanio del dataframe y con valores del 0 al tam-1\n",
        "indice = np.arange(tam)\n",
        "# Mezclamos los indices del vector que acabamos de crear\n",
        "np.random.shuffle(indice)\n",
        "\n",
        "# Declaramos df_shuffled para almacenar el dataframe con las lineas de la misma, pero esta vez mezclados para\n",
        "# evitar algun tipo de comportamiento en particular\n",
        "df_shuffled = dataframe.iloc[indice]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Jz4FlVl8Kte"
      },
      "source": [
        "# Aqui dividimos la data en tres dataframe\n",
        "\n",
        "# 1. Obtenemos desde la linea 0 hasta el indice tam_train - 1 y lo almacenamos en df_train\n",
        "# para el entrenamiento del modelo\n",
        "df_train = df_shuffled.iloc[:tam_train].copy() \n",
        "\n",
        "# 2. Obtenemos desde la ultima linea del indice de tam_train hasta el indice de tam_val -1\n",
        "# y lo almacenamos en df_val para validar el modelo de Machine Learning\n",
        "df_val = df_shuffled.iloc[tam_train:tam_train+tam_val].copy()\n",
        "\n",
        "# 3. Sumamos los indices de tam_train + tam_val - 1 para obtener el indice desde donde va a iniciar los datos\n",
        "# de df_test y termina hasta la ultima linea del dataframe\n",
        "df_test = df_shuffled.iloc[tam_train+tam_val:].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUrg2-JXnnnp"
      },
      "source": [
        "# imprimimos cada df para ver si la data se distribuyo a como queremos\n",
        "print('dimensiones del dataframe: ' + str(dataframe.shape))\n",
        "print('dimensiones del df_train: ' + str(df_train.shape))\n",
        "print('dimensiones del df_test: ' + str(df_test.shape))\n",
        "print('dimensiones del df_val: ' + str(df_val.shape))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}